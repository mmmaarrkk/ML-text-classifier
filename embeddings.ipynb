{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koles\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce GTX 1650 Ti\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from torch import nn\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train_row.csv')\n",
    "df_test = pd.read_csv('data/test_row.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEmbeddings:\n",
    "    def __init__(self, add_cls_embeddings=True, add_mean_embeddings=False):\n",
    "        self.add_mean_embeddings = add_mean_embeddings\n",
    "        self.add_cls_embeddings = add_cls_embeddings\n",
    "        if add_cls_embeddings is False and add_mean_embeddings is False:\n",
    "            raise 'Error: you should select at least one type of embeddings to be computed'\n",
    "\n",
    "    def mean_pooling(self, hidden_state, attention_mask):\n",
    "        \"\"\"\n",
    "        Возвращает усредненный с учетом attention_mask hidden_state.\n",
    "        \"\"\"\n",
    "        token_embeddings = hidden_state.detach().cpu()\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        return sum_embeddings / attention_mask.sum()\n",
    "\n",
    "    def extract_embeddings(self, texts, model_name, max_len):\n",
    "        \"\"\"\n",
    "        Возвращает значения посчитанные данной моделью эмбеддинги для всех текстов из texts.\n",
    "        \"\"\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModel.from_pretrained(model_name).cuda()\n",
    "        text_features = []\n",
    "        for sentence in tqdm(texts):\n",
    "            encoded_input = tokenizer([sentence],\n",
    "                                      padding='max_length',\n",
    "                                      truncation=True,\n",
    "                                      max_length=max_len,\n",
    "                                      return_tensors='pt')\n",
    "            with torch.no_grad():\n",
    "                hidden_state, cls_head = model(input_ids=encoded_input['input_ids'].cuda(), return_dict=False)\n",
    "                sentence_embeddings = self.mean_pooling(hidden_state, encoded_input['attention_mask'])\n",
    "\n",
    "            now_emb = []\n",
    "            if self.add_cls_embeddings:\n",
    "                now_emb.append(cls_head.detach().cpu().numpy().flatten())\n",
    "\n",
    "            if self.add_mean_embeddings:\n",
    "                now_emb.append(sentence_embeddings.detach().cpu().numpy().flatten())\n",
    "\n",
    "            text_features.append(np.concatenate(now_emb, axis=0))\n",
    "        return text_features\n",
    "\n",
    "    def add_many_embeddings(self, df, text_col, models):\n",
    "        \"\"\"\"\n",
    "        Добавляет в качестве признаков эмбеддинги для колонки text_col.\n",
    "        В качестве моделей и максимальных длинн используются models.\n",
    "        \"\"\"\n",
    "        for model_name, max_len in models:\n",
    "            print(model_name)\n",
    "            text_features = self.extract_embeddings(df[text_col], model_name, max_len)\n",
    "            text_features_df = pd.DataFrame(text_features, columns = [f'{model_name}_{text_col}_feature_{i}' for i in range(len(text_features[0]))])\n",
    "            df = df.join(text_features_df)\n",
    "            df.to_csv('data/transformers_text_features.csv', index=False)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "          ('cointegrated/LaBSE-en-ru', 512),\n",
    "          ('DeepPavlov/rubert-base-cased-conversational', 512)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cointegrated/LaBSE-en-ru\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4bad2a90954232afbb4bb43b64bf7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\koles\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:123: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\koles\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95710943ec447f5befd421efad5cb01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/806 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feea051412b04dea8eeda8c9da049cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/521k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f06a284718418c96d293445cd17756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e96bd7829a94259b6d5c0fe9079c543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/516M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/LaBSE-en-ru were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8296f2bb085248a58152d79ff8f8477c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepPavlov/rubert-base-cased-conversational\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc58e2194c44dc09653c7ed53da1f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc44a463fa045d0ab6eafd49392ad46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f778005ffda44d04a6d45834f1a5f23d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd9d4b906c1d43f396156da786df8e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8006061e834248fd9e2104053b6c90e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased-conversational were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3aa493837204d7183528faf62e34273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_embeddings = TextEmbeddings(True, True)\n",
    "data = text_embeddings.add_many_embeddings(df_train, 'text', models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>cointegrated/LaBSE-en-ru_text_feature_0</th>\n",
       "      <th>cointegrated/LaBSE-en-ru_text_feature_1</th>\n",
       "      <th>cointegrated/LaBSE-en-ru_text_feature_2</th>\n",
       "      <th>cointegrated/LaBSE-en-ru_text_feature_3</th>\n",
       "      <th>cointegrated/LaBSE-en-ru_text_feature_4</th>\n",
       "      <th>cointegrated/LaBSE-en-ru_text_feature_5</th>\n",
       "      <th>cointegrated/LaBSE-en-ru_text_feature_6</th>\n",
       "      <th>cointegrated/LaBSE-en-ru_text_feature_7</th>\n",
       "      <th>...</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_1526</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_1527</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_1528</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_1529</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_1530</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_1531</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_1532</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_1533</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_1534</th>\n",
       "      <th>DeepPavlov/rubert-base-cased-conversational_text_feature_1535</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>extreme</td>\n",
       "      <td>Ледник Пасторури это цирковой ледник расположе...</td>\n",
       "      <td>-0.076881</td>\n",
       "      <td>-0.412762</td>\n",
       "      <td>-0.056001</td>\n",
       "      <td>0.046433</td>\n",
       "      <td>-0.449512</td>\n",
       "      <td>-0.253624</td>\n",
       "      <td>-0.301378</td>\n",
       "      <td>-0.103132</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.783512</td>\n",
       "      <td>0.589172</td>\n",
       "      <td>-0.022016</td>\n",
       "      <td>-0.231998</td>\n",
       "      <td>0.875344</td>\n",
       "      <td>-0.112135</td>\n",
       "      <td>-0.048335</td>\n",
       "      <td>0.161959</td>\n",
       "      <td>0.981492</td>\n",
       "      <td>-0.298607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>martial_arts</td>\n",
       "      <td>Главные участники предстоящего Betokenoid 274 ...</td>\n",
       "      <td>-0.046052</td>\n",
       "      <td>-0.103519</td>\n",
       "      <td>-0.111545</td>\n",
       "      <td>-0.114912</td>\n",
       "      <td>0.039759</td>\n",
       "      <td>-0.388762</td>\n",
       "      <td>-0.350189</td>\n",
       "      <td>-0.019205</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.662196</td>\n",
       "      <td>0.968559</td>\n",
       "      <td>-0.271811</td>\n",
       "      <td>0.215214</td>\n",
       "      <td>1.008042</td>\n",
       "      <td>-0.207437</td>\n",
       "      <td>0.750243</td>\n",
       "      <td>0.188331</td>\n",
       "      <td>0.905672</td>\n",
       "      <td>-0.198813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>extreme</td>\n",
       "      <td>Ttokenoid Btokenoid – карта с которой можно не...</td>\n",
       "      <td>0.070633</td>\n",
       "      <td>-0.161732</td>\n",
       "      <td>0.134272</td>\n",
       "      <td>0.207949</td>\n",
       "      <td>0.076964</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>-0.030984</td>\n",
       "      <td>-0.070647</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.759897</td>\n",
       "      <td>0.173297</td>\n",
       "      <td>-0.612716</td>\n",
       "      <td>-0.515749</td>\n",
       "      <td>0.493288</td>\n",
       "      <td>-0.486974</td>\n",
       "      <td>0.029368</td>\n",
       "      <td>1.051441</td>\n",
       "      <td>0.681879</td>\n",
       "      <td>-1.202563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>autosport</td>\n",
       "      <td>В Сильверстоуне произошли крупные обновления а...</td>\n",
       "      <td>-0.181577</td>\n",
       "      <td>-0.094993</td>\n",
       "      <td>0.290002</td>\n",
       "      <td>0.184838</td>\n",
       "      <td>0.076357</td>\n",
       "      <td>-0.125468</td>\n",
       "      <td>0.171144</td>\n",
       "      <td>-0.018427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.697004</td>\n",
       "      <td>0.126595</td>\n",
       "      <td>-0.838320</td>\n",
       "      <td>-0.295631</td>\n",
       "      <td>1.008092</td>\n",
       "      <td>0.097092</td>\n",
       "      <td>-0.005237</td>\n",
       "      <td>0.303586</td>\n",
       "      <td>0.788490</td>\n",
       "      <td>-0.606932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>extreme</td>\n",
       "      <td>На протяжении более чем 30 лет Вестсайд являет...</td>\n",
       "      <td>-0.077018</td>\n",
       "      <td>-0.280560</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>0.345588</td>\n",
       "      <td>-0.185279</td>\n",
       "      <td>-0.234000</td>\n",
       "      <td>-0.023668</td>\n",
       "      <td>-0.418108</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.526097</td>\n",
       "      <td>0.874269</td>\n",
       "      <td>-0.634377</td>\n",
       "      <td>0.069256</td>\n",
       "      <td>0.950486</td>\n",
       "      <td>-0.208337</td>\n",
       "      <td>0.473491</td>\n",
       "      <td>0.558341</td>\n",
       "      <td>1.220464</td>\n",
       "      <td>-1.187832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3074 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       category                                               text  \\\n",
       "0       extreme  Ледник Пасторури это цирковой ледник расположе...   \n",
       "1  martial_arts  Главные участники предстоящего Betokenoid 274 ...   \n",
       "2       extreme  Ttokenoid Btokenoid – карта с которой можно не...   \n",
       "3     autosport  В Сильверстоуне произошли крупные обновления а...   \n",
       "4       extreme  На протяжении более чем 30 лет Вестсайд являет...   \n",
       "\n",
       "   cointegrated/LaBSE-en-ru_text_feature_0  \\\n",
       "0                                -0.076881   \n",
       "1                                -0.046052   \n",
       "2                                 0.070633   \n",
       "3                                -0.181577   \n",
       "4                                -0.077018   \n",
       "\n",
       "   cointegrated/LaBSE-en-ru_text_feature_1  \\\n",
       "0                                -0.412762   \n",
       "1                                -0.103519   \n",
       "2                                -0.161732   \n",
       "3                                -0.094993   \n",
       "4                                -0.280560   \n",
       "\n",
       "   cointegrated/LaBSE-en-ru_text_feature_2  \\\n",
       "0                                -0.056001   \n",
       "1                                -0.111545   \n",
       "2                                 0.134272   \n",
       "3                                 0.290002   \n",
       "4                                 0.147400   \n",
       "\n",
       "   cointegrated/LaBSE-en-ru_text_feature_3  \\\n",
       "0                                 0.046433   \n",
       "1                                -0.114912   \n",
       "2                                 0.207949   \n",
       "3                                 0.184838   \n",
       "4                                 0.345588   \n",
       "\n",
       "   cointegrated/LaBSE-en-ru_text_feature_4  \\\n",
       "0                                -0.449512   \n",
       "1                                 0.039759   \n",
       "2                                 0.076964   \n",
       "3                                 0.076357   \n",
       "4                                -0.185279   \n",
       "\n",
       "   cointegrated/LaBSE-en-ru_text_feature_5  \\\n",
       "0                                -0.253624   \n",
       "1                                -0.388762   \n",
       "2                                 0.045200   \n",
       "3                                -0.125468   \n",
       "4                                -0.234000   \n",
       "\n",
       "   cointegrated/LaBSE-en-ru_text_feature_6  \\\n",
       "0                                -0.301378   \n",
       "1                                -0.350189   \n",
       "2                                -0.030984   \n",
       "3                                 0.171144   \n",
       "4                                -0.023668   \n",
       "\n",
       "   cointegrated/LaBSE-en-ru_text_feature_7  ...  \\\n",
       "0                                -0.103132  ...   \n",
       "1                                -0.019205  ...   \n",
       "2                                -0.070647  ...   \n",
       "3                                -0.018427  ...   \n",
       "4                                -0.418108  ...   \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_1526  \\\n",
       "0                                          -0.783512               \n",
       "1                                          -0.662196               \n",
       "2                                          -0.759897               \n",
       "3                                          -0.697004               \n",
       "4                                          -0.526097               \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_1527  \\\n",
       "0                                           0.589172               \n",
       "1                                           0.968559               \n",
       "2                                           0.173297               \n",
       "3                                           0.126595               \n",
       "4                                           0.874269               \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_1528  \\\n",
       "0                                          -0.022016               \n",
       "1                                          -0.271811               \n",
       "2                                          -0.612716               \n",
       "3                                          -0.838320               \n",
       "4                                          -0.634377               \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_1529  \\\n",
       "0                                          -0.231998               \n",
       "1                                           0.215214               \n",
       "2                                          -0.515749               \n",
       "3                                          -0.295631               \n",
       "4                                           0.069256               \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_1530  \\\n",
       "0                                           0.875344               \n",
       "1                                           1.008042               \n",
       "2                                           0.493288               \n",
       "3                                           1.008092               \n",
       "4                                           0.950486               \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_1531  \\\n",
       "0                                          -0.112135               \n",
       "1                                          -0.207437               \n",
       "2                                          -0.486974               \n",
       "3                                           0.097092               \n",
       "4                                          -0.208337               \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_1532  \\\n",
       "0                                          -0.048335               \n",
       "1                                           0.750243               \n",
       "2                                           0.029368               \n",
       "3                                          -0.005237               \n",
       "4                                           0.473491               \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_1533  \\\n",
       "0                                           0.161959               \n",
       "1                                           0.188331               \n",
       "2                                           1.051441               \n",
       "3                                           0.303586               \n",
       "4                                           0.558341               \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_1534  \\\n",
       "0                                           0.981492               \n",
       "1                                           0.905672               \n",
       "2                                           0.681879               \n",
       "3                                           0.788490               \n",
       "4                                           1.220464               \n",
       "\n",
       "   DeepPavlov/rubert-base-cased-conversational_text_feature_1535  \n",
       "0                                          -0.298607              \n",
       "1                                          -0.198813              \n",
       "2                                          -1.202563              \n",
       "3                                          -0.606932              \n",
       "4                                          -1.187832              \n",
       "\n",
       "[5 rows x 3074 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% gpu memory available for training. Free: 1762.700001 Total: 4096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.126016\n",
      "0:\tlearn: 2.4603198\ttest: 2.4687300\tbest: 2.4687300 (0)\ttotal: 424ms\tremaining: 7m 3s\n",
      "100:\tlearn: 0.7353239\ttest: 1.2503710\tbest: 1.2503710 (100)\ttotal: 32.5s\tremaining: 4m 49s\n",
      "200:\tlearn: 0.4652716\ttest: 1.1264506\tbest: 1.1264506 (200)\ttotal: 1m 1s\tremaining: 4m 2s\n",
      "300:\tlearn: 0.3300544\ttest: 1.0686409\tbest: 1.0686409 (300)\ttotal: 1m 28s\tremaining: 3m 25s\n",
      "400:\tlearn: 0.2534932\ttest: 1.0330588\tbest: 1.0330588 (400)\ttotal: 1m 54s\tremaining: 2m 50s\n",
      "500:\tlearn: 0.2031064\ttest: 1.0082665\tbest: 1.0082665 (500)\ttotal: 2m 20s\tremaining: 2m 19s\n",
      "600:\tlearn: 0.1652963\ttest: 0.9875378\tbest: 0.9875378 (600)\ttotal: 2m 45s\tremaining: 1m 50s\n",
      "700:\tlearn: 0.1376393\ttest: 0.9718162\tbest: 0.9718162 (700)\ttotal: 3m 11s\tremaining: 1m 21s\n",
      "800:\tlearn: 0.1151603\ttest: 0.9596920\tbest: 0.9593813 (799)\ttotal: 3m 37s\tremaining: 54s\n",
      "900:\tlearn: 0.0987487\ttest: 0.9519076\tbest: 0.9519076 (900)\ttotal: 4m 3s\tremaining: 26.7s\n",
      "999:\tlearn: 0.0850986\ttest: 0.9453007\tbest: 0.9453007 (999)\ttotal: 4m 28s\tremaining: 0us\n",
      "bestTest = 0.9453006999\n",
      "bestIteration = 999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x17de21e6560>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import catboost as cb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "X = data.drop(['category', 'text'], axis=1)\n",
    "y = data['category'].astype('category')\n",
    "num_classes = y.nunique()\n",
    "cat_features = ['category']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "train_pool = cb.Pool(X_train, y_train)\n",
    "test_pool = cb.Pool(X_test, y_test)\n",
    "\n",
    "model = cb.CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    depth=6,\n",
    "    loss_function='MultiClass',\n",
    "    classes_count=num_classes,\n",
    "    verbose=100,\n",
    "    task_type=\"GPU\",\n",
    "    devices='0'\n",
    ")\n",
    "model.fit(train_pool, eval_set=test_pool, early_stopping_rounds=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learn': {'MultiClass': 0.08509856160481771},\n",
       " 'validation': {'MultiClass': 0.9453006998697917}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>cointegrated/LaBSE-en-ru_text_feature_1483</td>\n",
       "      <td>1.107499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>cointegrated/LaBSE-en-ru_text_feature_1446</td>\n",
       "      <td>1.080637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>cointegrated/LaBSE-en-ru_text_feature_862</td>\n",
       "      <td>0.955099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>cointegrated/LaBSE-en-ru_text_feature_958</td>\n",
       "      <td>0.943007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>cointegrated/LaBSE-en-ru_text_feature_1284</td>\n",
       "      <td>0.939991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>DeepPavlov/rubert-base-cased-conversational_te...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>DeepPavlov/rubert-base-cased-conversational_te...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>DeepPavlov/rubert-base-cased-conversational_te...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>DeepPavlov/rubert-base-cased-conversational_te...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>DeepPavlov/rubert-base-cased-conversational_te...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3072 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Feature  Importance\n",
       "1483         cointegrated/LaBSE-en-ru_text_feature_1483    1.107499\n",
       "1446         cointegrated/LaBSE-en-ru_text_feature_1446    1.080637\n",
       "862           cointegrated/LaBSE-en-ru_text_feature_862    0.955099\n",
       "958           cointegrated/LaBSE-en-ru_text_feature_958    0.943007\n",
       "1284         cointegrated/LaBSE-en-ru_text_feature_1284    0.939991\n",
       "...                                                 ...         ...\n",
       "2080  DeepPavlov/rubert-base-cased-conversational_te...    0.000000\n",
       "2079  DeepPavlov/rubert-base-cased-conversational_te...    0.000000\n",
       "2078  DeepPavlov/rubert-base-cased-conversational_te...    0.000000\n",
       "2076  DeepPavlov/rubert-base-cased-conversational_te...    0.000000\n",
       "1536  DeepPavlov/rubert-base-cased-conversational_te...    0.000000\n",
       "\n",
       "[3072 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = model.get_feature_importance(data=train_pool, type=cb.EFstrType.PredictionValuesChange)\n",
    "\n",
    "feature_importances_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2165, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_feature_importances_df = feature_importances_df[feature_importances_df['Importance'] < 0.02]\n",
    "drop_feature_importances_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned = data.drop(drop_feature_importances_df['Feature'].to_list(), axis=1)\n",
    "\n",
    "train_cleaned.to_csv('data/transformers_text_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
